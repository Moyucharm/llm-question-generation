# 任务书 - QGen 智能出题与在线考试系统

## 1. 项目概述

本项目面向教学场景，提供 **AI 智能出题、在线考试与自动批改** 能力，支持题库管理与知识点体系化组织。

**核心价值主张**：
- 🎯 **教师**：AI 辅助出题 + 多模型质量审核 + 人工二次批改
- 📚 **学生**：AI 生成练习 + 重复练习 + 成绩追踪
- ⚡ **系统**：三阶段质量控制流水线 + 完整考试闭环

**目标教学闭环**：
```
课程/知识点 → AI出题 → 教师审阅 → 题库 → 组卷 → 考试发布 → 学生答题 → AI批改 → 教师复核 → 成绩发布
```

## 2. 当前进度与问题分析

### ✅ 已完成功能

| 模块 | 状态 | 说明 |
|------|------|------|
| 用户认证 | ✅ | JWT 登录/注册/Token 管理 |
| 课程管理 | ✅ | 课程与知识点树形 CRUD |
| 题库管理 | ✅ | 题目 CRUD、JSON 导入导出 |
| AI 出题 | ✅ | 三阶段流水线（Generator → Validator → Reviewer） |
| 考试管理 | ✅ | 创建/发布/参加/客观题自动评分 |
| 仪表板 UI | ✅ | 侧边栏+顶栏+卡片设计 |

### ❌ 存在的核心问题

#### 问题1：AI 出题功能太独立，缺乏与教学流程的整合

**现状**：
- AI 生成题目后直接进入"做题"流程
- 教师无法在出题后进行审阅和编辑
- 生成的题目是一次性的，无法保存到题库

**影响**：
- 教师难以控制题目质量
- AI 生成的题目无法复用
- 出题功能与题库/考试系统脱节

#### 问题2：学生练习功能不完整

**现状**：
- 学生只能"一边生成一边做"
- 生成的练习无法保存
- 无法重复练习同一套题目

**影响**：
- 学生无法针对薄弱点反复练习
- 练习记录无法追踪
- 学习效果难以评估

#### 问题3：成绩管理体系缺失

**现状**：
- 学生提交考试后看不到成绩
- 教师无法查看学生的答卷详情
- AI 批改结果无法被教师复核
- 没有成绩统计和分析功能

**影响**：
- 考试闭环不完整
- 教师无法进行教学评估
- AI 批改错误无法纠正

#### 问题4：班级管理是否必要？

**分析**：
- 生产环境中，考试通常发布给特定班级
- 但对于毕设项目，完整的班级管理系统过于复杂
- **建议**：简化处理，暂不实现班级管理，考试发布给所有学生

## 3. 解决方案设计

### 方案1：重构 AI 出题流程（教师端）

```
教师选择课程/知识点 → AI 生成题目 → 教师审阅界面 → 编辑/修改/删除 → 批量保存到题库
                                         ↓
                              多模型质量评估（可选）
```

**关键功能**：
- [ ] 出题后进入"审阅模式"而非"做题模式"
- [ ] 教师可编辑每道题的题干、选项、答案、解析
- [ ] 支持批量保存到题库（关联课程/知识点）
- [ ] 可选：调用第二个 LLM 对题目质量进行评估

### 方案2：学生练习系统

```
学生选择课程/知识点 → AI 生成练习 → 答题 → AI 批改 → 保存练习记录
                                                    ↓
                                           可重复练习该记录
```

**关键功能**：
- [ ] 学生生成的练习保存为"练习记录"
- [ ] 练习记录列表页面
- [ ] 支持重新做同一套题目
- [ ] 练习成绩统计

### 方案3：完善考试成绩管理

```
学生提交 → AI 批改（客观题自动评分 + 主观题 AI 评分）→ 教师复核 → 最终成绩发布
                                                        ↓
                                               教师可修改 AI 评分
```

**关键功能**：
- [ ] 学生提交后可查看初步成绩（客观题）
- [ ] 教师答卷列表页面（查看所有学生答卷）
- [ ] 教师答卷详情页面（逐题查看 + 修改评分）
- [ ] AI 主观题批改 + 教师复核
- [ ] 最终成绩确认与发布

## 4. 任务清单（按优先级重排）

### P0 - 核心闭环（必须完成）

#### 4.1 考试成绩管理体系 ⭐ 最高优先级

**理由**：这是考试系统最核心的闭环，没有成绩管理，整个考试功能形同虚设。

| 任务 | 说明 | 前端 | 后端 |
|------|------|------|------|
| 学生成绩查看 | 提交后显示客观题得分 | ✓ | ✓ |
| 教师答卷列表 | 查看考试的所有答卷 | ✓ | ✓ |
| 教师答卷详情 | 查看学生答案 + AI 评分 | ✓ | ✓ |
| 教师修改评分 | 可调整每道题的得分 | ✓ | ✓ |
| 成绩确认发布 | 教师确认最终成绩 | ✓ | ✓ |

**数据模型调整**：
```python
# attempts 表新增字段
final_score: Optional[float]  # 教师确认的最终成绩
is_graded_by_teacher: bool = False  # 是否经过教师复核
graded_at: Optional[datetime]  # 批改时间

# attempt_answers 表新增字段
ai_score: Optional[float]  # AI 评分
teacher_score: Optional[float]  # 教师评分（可覆盖 AI）
ai_feedback: Optional[str]  # AI 评语
teacher_feedback: Optional[str]  # 教师评语
```

#### 4.2 AI 主观题批改

| 任务 | 说明 |
|------|------|
| 批改 API | `/api/exams/{id}/grade` 触发 AI 批改 |
| 批改服务 | 简答题调用 LLM 评分 + 生成评语 |
| 批改结果存储 | 存入 attempt_answers 表 |
| 批量批改 | 支持教师一键批改所有未批改答卷 |

#### 4.3 权限与角色完善

| 任务 | 说明 |
|------|------|
| 教师专属功能 | 创建考试、查看答卷、修改成绩 |
| 学生专属功能 | 参加考试、查看自己成绩 |
| 前端权限控制 | 根据角色显示/隐藏功能入口 |

### P1 - 教学增强（重要）

#### 4.4 AI 出题流程重构（教师端）

| 任务 | 说明 |
|------|------|
| 审阅模式 | 出题后进入题目审阅页面（非做题） |
| 题目编辑 | 教师可修改题干/选项/答案/解析 |
| 批量保存 | 一键保存到题库 |
| 质量评估 | 可选：第二个 LLM 评估题目质量 |

#### 4.5 学生练习系统

| 任务 | 说明 |
|------|------|
| 练习记录保存 | AI 生成的练习存入数据库 |
| 练习记录列表 | 学生查看历史练习 |
| 重复练习 | 重新做同一套题 |
| 练习成绩统计 | 正确率、薄弱知识点 |

**数据模型**：
```python
# 新增 practices 表（练习记录）
class Practice(Base):
    id: int
    student_id: int  # 学生
    course_id: Optional[int]  # 关联课程
    knowledge_point_id: Optional[int]  # 关联知识点
    questions: JSON  # 题目快照
    created_at: datetime

# 新增 practice_attempts 表（练习答题记录）
class PracticeAttempt(Base):
    id: int
    practice_id: int
    answers: JSON  # 答案
    score: float  # 得分
    completed_at: datetime
```

### P2 - 可选增强

#### 4.6 试卷管理

| 任务 | 说明 |
|------|------|
| 试卷 CRUD | 创建/编辑/删除试卷 |
| 从题库选题 | 添加题库题目到试卷 |
| 考试绑定试卷 | 考试创建时选择试卷 |

**说明**：当前考试已支持直接添加题目，试卷管理为锦上添花功能。

#### 4.7 学习分析与统计

| 任务 | 说明 |
|------|------|
| 错题本 | 学生查看答错的题目 |
| 薄弱点分析 | 按知识点统计正确率 |
| 班级统计 | 教师查看考试整体情况 |

#### 4.8 班级管理（不建议本期实现）

**理由**：
- 完整的班级管理需要：班级 CRUD、学生归属、教师归属、考试发布范围
- 对于毕设演示，可以简化为"考试对所有学生可见"
- 如时间充裕可考虑简化版：教师创建考试时选择"公开/仅特定用户"

## 5. 里程碑规划

### M1：考试成绩闭环（最优先）

**目标**：学生能看到成绩，教师能批改和确认成绩

**交付物**：
- [ ] 学生答题后显示客观题得分
- [ ] 教师答卷列表与详情页面
- [ ] 教师修改评分功能
- [ ] 成绩确认与发布

**验收标准**：
- 学生提交考试后能看到初步分数
- 教师能查看任意学生的答卷详情
- 教师能修改每道题的评分
- 教师确认后学生看到最终成绩

### M2：AI 批改完善

**目标**：主观题 AI 批改 + 教师复核

**交付物**：
- [ ] AI 批改 API（简答题）
- [ ] AI 评分与评语展示
- [ ] 教师复核并覆盖 AI 评分

**验收标准**：
- 简答题有 AI 评分和评语
- 教师可以修改 AI 的评分
- 最终成绩以教师确认为准

### M3：教学增强（可选）

**目标**：完善出题和练习流程

**交付物**：
- [ ] 教师出题审阅模式
- [ ] 学生练习记录保存与重复练习
- [ ] 学习统计基础功能

## 6. 验收标准（按角色）

### 教师视角

| 功能 | 验收标准 |
|------|----------|
| AI 出题 | 生成题目后可审阅、编辑、保存到题库 |
| 考试管理 | 可创建/发布/关闭考试 |
| 答卷批改 | 可查看学生答卷、修改评分、确认成绩 |
| 成绩统计 | 可查看考试整体得分情况 |

### 学生视角

| 功能 | 验收标准 |
|------|----------|
| AI 练习 | 可生成练习、答题、查看结果、重复练习 |
| 参加考试 | 可查看可参加的考试、答题、提交 |
| 查看成绩 | 提交后可看到分数（初步/最终） |

## 7. 技术要点

### 成绩状态机

```
学生提交 (submitted)
    ↓
客观题自动评分 → 显示初步成绩
    ↓
AI 批改主观题 (ai_graded)
    ↓
教师复核 (teacher_reviewed)
    ↓
成绩确认发布 (graded)
```

### API 设计预览

```
# 成绩管理
GET  /api/exams/{id}/attempts          # 教师：获取所有答卷
GET  /api/exams/{id}/attempts/{aid}    # 教师：获取答卷详情
PUT  /api/exams/{id}/attempts/{aid}    # 教师：修改评分
POST /api/exams/{id}/attempts/{aid}/confirm  # 教师：确认成绩

# AI 批改
POST /api/exams/{id}/grade             # 触发 AI 批改
POST /api/exams/{id}/attempts/{aid}/grade  # 批改单份答卷

# 练习系统（P1）
POST /api/practices                    # 创建练习记录
GET  /api/practices                    # 获取练习列表
GET  /api/practices/{id}               # 获取练习详情
POST /api/practices/{id}/attempt       # 提交练习答案
```

## 8. 风险与应对

| 风险 | 影响 | 应对措施 |
|------|------|----------|
| LLM 批改不准确 | 成绩不公正 | 教师复核机制，AI 评分仅作参考 |
| 开发时间不足 | 功能不完整 | 优先完成 M1（成绩闭环），其他可选 |
| 数据模型变更 | 现有数据兼容 | 增量添加字段，设置合理默认值 |

## 9. 建议开发顺序

```
1. 后端：成绩相关字段添加 + API 开发
2. 前端：学生成绩查看页面
3. 前端：教师答卷列表与详情页面
4. 前端：教师修改评分功能
5. 后端：AI 批改服务
6. 前端：AI 批改结果展示
7. 整合测试：完整考试流程
```

---

*最后更新：根据项目实际问题重新规划，聚焦于考试成绩闭环*
